{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3253,"status":"ok","timestamp":1647914056394,"user":{"displayName":"Đức Nguyễn Thanh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17339142369468246592"},"user_tz":-420},"id":"Mws1_PWqdz5W","outputId":"29ed4012-c4a6-430d-ef41-a9ebb98f9e41"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/nguyen.van.quan/miniconda3/envs/mmseg/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import argparse\n","import logging\n","import os\n","import random\n","import sys\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from mcode.utils import clip_gradient, AvgMeter\n","\n","from glob import glob\n","from skimage.io import imread\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from collections import OrderedDict\n","from torch.autograd import Variable\n","from datetime import datetime\n","import torch.nn.functional as F\n","import cv2\n","from albumentations.augmentations import transforms\n","from albumentations.core.composition import Compose, OneOf\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NFSNX-9CITYi"},"outputs":[],"source":["import argparse\n","import copy\n","import os\n","import os.path as osp\n","import time\n","\n","import mmcv\n","import torch\n","from mmcv.runner import init_dist\n","from mmcv.utils import Config, DictAction, get_git_hash\n","\n","from mmseg import __version__\n","from mmseg.apis import set_random_seed, train_segmentor\n","from mmseg.datasets import build_dataset\n","from mmseg.models import build_segmentor\n","from mmseg.utils import collect_env, get_root_logger"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"GkBRZqjXJ82d"},"outputs":[],"source":["# model segformerb4 settings\n","from mmseg.models import build_segmentor\n","from mmcv.runner.optimizer import build_optimizer\n","import torch\n","\n","def segformer(arch):\n","    num_layers = []\n","    pretrained = f'pretrained/mit_{arch}_mmseg.pth'\n","    if arch == 'b1':\n","        num_layers = [2,2,2,2]\n","    if arch == 'b2':\n","        num_layers = [3, 4, 6, 3 ]\n","    if arch == 'b3':\n","        num_layers = [3, 4, 18, 3]\n","    if arch == 'b4':\n","        num_layers = [3, 8, 27, 3]\n","    model = dict(\n","        type='SunSegmentor',\n","        backbone=dict(\n","            type='MixVisionTransformer',\n","            in_channels=3,\n","            embed_dims=64,\n","            num_stages=4,\n","            num_layers=num_layers,\n","            num_heads=[1, 2, 5, 8],\n","            patch_sizes=[7, 3, 3, 3],\n","            sr_ratios=[8, 4, 2, 1],\n","            out_indices=(0, 1, 2, 3),\n","            mlp_ratio=4,\n","            qkv_bias=True,\n","            drop_rate=0.0,\n","            attn_drop_rate=0.0,\n","            drop_path_rate=0.1,\n","            pretrained=pretrained),\n","        decode_head=dict(\n","            type='DRPHead',\n","            in_channels=[64, 128, 320, 512],\n","            in_index=[0, 1, 2, 3],\n","            channels=128,\n","            dropout_ratio=0.1,\n","            num_classes=1,\n","            norm_cfg=dict(type='BN', requires_grad=True),\n","            align_corners=False,\n","            loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),\n","        # model training and testing settings\n","        train_cfg=dict(),\n","        test_cfg=dict(mode='whole'))\n","    model = build_segmentor(model)\n","    model.init_weights()\n","    return model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Q6wyzylvHpln"},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, img_paths, mask_paths, aug=True, transform=None):\n","        self.img_paths = img_paths\n","        self.mask_paths = mask_paths\n","        self.aug = aug\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_paths[idx]\n","        mask_path = self.mask_paths[idx]\n","        # image = imread(img_path)\n","        # mask = imread(mask_path)\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(mask_path, 0)\n","        # name = self.img_paths[idx].split('/')[-1]\n","\n","        if self.transform is not None:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","        else:\n","            image = cv2.resize(image, (352, 352))\n","            mask = cv2.resize(mask, (352, 352)) \n","\n","        image = image.astype('float32') / 255\n","        image = image.transpose((2, 0, 1))\n","\n","        mask = mask[:,:,np.newaxis]\n","        mask = mask.astype('float32') / 255\n","        mask = mask.transpose((2, 0, 1))\n","\n","        return np.asarray(image), np.asarray(mask)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"pFfhy7JCJmJI"},"outputs":[],"source":["epsilon = 1e-7\n","def recall_m(y_true, y_pred):\n","  true_positives = torch.sum(torch.round(torch.clip(y_true * y_pred, 0, 1)))\n","  possible_positives = torch.sum(torch.round(torch.clip(y_true, 0, 1)))\n","  recall = true_positives / (possible_positives + epsilon)\n","  return recall\n","\n","def precision_m(y_true, y_pred):\n","  true_positives = torch.sum(torch.round(torch.clip(y_true * y_pred, 0, 1)))\n","  predicted_positives = torch.sum(torch.round(torch.clip(y_pred, 0, 1)))\n","  precision = true_positives / (predicted_positives + epsilon)\n","  return precision\n","\n","def dice_m(y_true, y_pred):\n","  precision = precision_m(y_true, y_pred)\n","  recall = recall_m(y_true, y_pred)\n","  return 2*((precision*recall)/(precision+recall+epsilon))\n","\n","def iou_m(y_true, y_pred):\n","  precision = precision_m(y_true, y_pred)\n","  recall = recall_m(y_true, y_pred)\n","  return recall*precision/(recall+precision-recall*precision +epsilon)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pm_aSeXoJoC3"},"outputs":[],"source":["class FocalLossV1(nn.Module):\n","\n","    def __init__(self,\n","                 alpha=0.25,\n","                 gamma=2,\n","                 reduction='mean',):\n","        super(FocalLossV1, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.reduction = reduction\n","        self.crit = nn.BCEWithLogitsLoss(reduction='none')\n","\n","    def forward(self, logits, label):\n","        # compute loss\n","        logits = logits.float() # use fp32 if logits is fp16\n","        with torch.no_grad():\n","            alpha = torch.empty_like(logits).fill_(1 - self.alpha)\n","            alpha[label == 1] = self.alpha\n","\n","        probs = torch.sigmoid(logits)\n","        pt = torch.where(label == 1, probs, 1 - probs)\n","        ce_loss = self.crit(logits, label.float())\n","        loss = (alpha * torch.pow(1 - pt, self.gamma) * ce_loss)\n","        if self.reduction == 'mean':\n","            loss = loss.mean()\n","        if self.reduction == 'sum':\n","            loss = loss.sum()\n","        return loss\n","\n","def structure_loss(pred, mask):\n","    weit = 1 + 5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)\n","    wfocal = FocalLossV1()(pred, mask)\n","    wfocal = (wfocal*weit).sum(dim=(2,3)) / weit.sum(dim=(2, 3))\n","\n","    pred = torch.sigmoid(pred)\n","    inter = ((pred * mask)*weit).sum(dim=(2, 3))\n","    union = ((pred + mask)*weit).sum(dim=(2, 3))\n","    wiou = 1 - (inter + 1)/(union - inter+1)\n","    return (wfocal + wiou).mean()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"z8M-oyZNJqUL"},"outputs":[],"source":["def train(train_loader, model, optimizer, epoch, lr_scheduler, deep=False):\n","    model.train()\n","    # ---- multi-scale training ----\n","    size_rates = [0.75, 1, 1.25]\n","    loss_record = AvgMeter()\n","    dice, iou = AvgMeter(), AvgMeter()\n","    for i, pack in enumerate(train_loader, start=1):\n","        if epoch <= 1:\n","                optimizer.param_groups[0][\"lr\"] = (epoch * i) / (1.0 * total_step) * init_lr\n","        else:\n","            lr_scheduler.step()\n","\n","        for rate in size_rates: \n","            optimizer.zero_grad()\n","            # ---- data prepare ----\n","            images, gts = pack\n","            images = Variable(images).cuda(1)\n","            gts = Variable(gts).cuda(1)\n","            # ---- rescale ----\n","            trainsize = int(round(trainsize_init*rate/32)*32)\n","            images = F.upsample(images, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n","            gts = F.upsample(gts, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n","            # ---- forward ----\n","            map5, map4, map3, map2, map1 = model(images)\n","            map1 = F.upsample(map1, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n","            map2 = F.upsample(map2, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n","            map3 = F.upsample(map3, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n","            map4 = F.upsample(map4, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n","            map5 = F.upsample(map5, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n","            loss = structure_loss(map1, gts) + structure_loss(map2, gts) + structure_loss(map3, gts) + structure_loss(map4, gts) + structure_loss(map5, gts)\n","            # ---- metrics ----\n","            dice_score = dice_m(map2, gts)\n","            iou_score = iou_m(map2, gts)\n","            # ---- backward ----\n","            loss.backward()\n","            clip_gradient(optimizer, clip)\n","            optimizer.step()\n","            # ---- recording loss ----\n","            if rate == 1:\n","                loss_record.update(loss.data, batchsize)\n","                dice.update(dice_score.data, batchsize)\n","                iou.update(iou_score.data, batchsize)\n","\n","        # ---- train visualization ----\n","        if i == total_step:\n","            print('{} Training Epoch [{:03d}/{:03d}], '\n","                  '[loss: {:0.4f}, dice: {:0.4f}, iou: {:0.4f}]'.\n","                  format(datetime.now(), epoch, num_epochs,\\\n","                         loss_record.show(), dice.show(), iou.show()))\n","\n","    ckpt_path = save_path + 'last.pth'\n","    print('[Saving Checkpoint:]', ckpt_path)\n","    checkpoint = {\n","        'epoch': epoch + 1,\n","        'state_dict': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'scheduler': lr_scheduler.state_dict()\n","    }\n","    torch.save(checkpoint, ckpt_path)\n","\n","    log = OrderedDict([\n","        ('loss', loss_record.show()), ('dice', dice.show()), ('iou', iou.show()),\n","    ])\n","\n","    return log"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"AFOm9drLJslH"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/nguyen.van.quan/miniconda3/envs/mmseg/lib/python3.9/site-packages/albumentations/augmentations/transforms.py:1149: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n","  warnings.warn(\n","/home/nguyen.van.quan/miniconda3/envs/mmseg/lib/python3.9/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n","  warnings.warn(\n"]}],"source":["def recall_np(y_true, y_pred):\n","    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + epsilon)\n","    return recall\n","\n","def precision_np(y_true, y_pred):\n","    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + epsilon)\n","    return precision\n","\n","def dice_np(y_true, y_pred):\n","    precision = precision_np(y_true, y_pred)\n","    recall = recall_np(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+epsilon))\n","\n","def iou_np(y_true, y_pred):\n","    intersection = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n","    union = np.sum(y_true)+np.sum(y_pred)-intersection\n","    return intersection/(union+epsilon)\n","\n","def get_scores(gts, prs):\n","    mean_precision = 0\n","    mean_recall = 0\n","    mean_iou = 0\n","    mean_dice = 0\n","    for gt, pr in zip(gts, prs):\n","        mean_precision += precision_np(gt, pr)\n","        mean_recall += recall_np(gt, pr)\n","        mean_iou += iou_np(gt, pr)\n","        mean_dice += dice_np(gt, pr)\n","\n","    mean_precision /= len(gts)\n","    mean_recall /= len(gts)\n","    mean_iou /= len(gts)\n","    mean_dice /= len(gts)        \n","    \n","    print(f\"scores: dice={mean_dice}, miou={mean_iou}, precision={mean_precision}, recall={mean_recall}\")\n","\n","    return (mean_iou, mean_dice, mean_precision, mean_recall)\n","\n","from mcode.config import *\n","from tabulate import tabulate\n","\n","def inference(model):\n","    print(\"#\" * 20)\n","    model.eval()\n","    dataset_names = ['Kvasir', 'CVC-ClinicDB', 'CVC-ColonDB', 'CVC-300', 'ETIS-LaribPolypDB']\n","    table = []\n","    headers = ['Dataset', 'IoU', 'Dice']\n","    ious, dices = AverageMeter(), AverageMeter()\n","\n","    for dataset_name in dataset_names:\n","        data_path = f'{test_folder}/{dataset_name}'\n","        X_test = glob.glob('{}/images/*'.format(data_path))\n","        X_test.sort()\n","        y_test = glob.glob('{}/masks/*'.format(data_path))\n","        y_test.sort()\n","\n","        test_dataset = Dataset(X_test, y_test)\n","        test_loader = torch.utils.data.DataLoader(\n","            test_dataset,\n","            batch_size=1,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False)\n","\n","        print('Dataset_name:', dataset_name)\n","        tp_all = 0\n","        fp_all = 0\n","        fn_all = 0\n","        mean_iou = 0\n","        gts = []\n","        prs = []\n","        for i, pack in enumerate(test_loader, start=1):\n","            image, gt = pack\n","            # name = name[0]\n","            gt = gt[0][0]\n","            gt = np.asarray(gt, np.float32)\n","            image = image.cuda(1)\n","\n","            res, res2, res3, res4, res5 = model(image)\n","            res = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n","            res = res.sigmoid().data.cpu().numpy().squeeze()\n","            res = (res - res.min()) / (res.max() - res.min() + 1e-8)\n","            pr = res.round()\n","            gts.append(gt)\n","            prs.append(pr)\n","            # cv2.imwrite(os.path.join(save_path, dataset_name, name), res)\n","        mean_iou, mean_dice, _, _ = get_scores(gts, prs)\n","        ious.update(mean_iou)\n","        dices.update(mean_dice)\n","        table.append([dataset_name, mean_iou, mean_dice])\n","    table.append(['Total', ious.avg, dices.avg])\n","    print(tabulate(table, headers=headers, tablefmt=\"fancy_grid\"))\n","    print(\"#\"*20)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Sq_wUsi6t3eo"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/nguyen.van.quan/Polyp/mmseg/models/backbones/mit.py:365: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n","  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n","/home/nguyen.van.quan/Polyp/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  warnings.warn(\n","2023-01-09 03:37:38,981 - mmcv - INFO - initialize MixVisionTransformer with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/mit_b1_mmseg.pth'}\n","2023-01-09 03:37:38,981 - mmcv - INFO - load model from: pretrained/mit_b1_mmseg.pth\n","2023-01-09 03:37:38,983 - mmcv - INFO - load checkpoint from local path: pretrained/mit_b1_mmseg.pth\n"]},{"name":"stdout","output_type":"stream","text":["Save path existed\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-09 03:37:39,074 - mmcv - INFO - initialize DRPHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n","2023-01-09 03:37:39,085 - mmcv - INFO - \n","backbone.layers.0.0.projection.weight - torch.Size([64, 3, 7, 7]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,085 - mmcv - INFO - \n","backbone.layers.0.0.projection.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,086 - mmcv - INFO - \n","backbone.layers.0.0.norm.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,086 - mmcv - INFO - \n","backbone.layers.0.0.norm.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,087 - mmcv - INFO - \n","backbone.layers.0.1.0.norm1.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,087 - mmcv - INFO - \n","backbone.layers.0.1.0.norm1.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,088 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.attn.in_proj_weight - torch.Size([192, 64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,088 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.attn.in_proj_bias - torch.Size([192]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,089 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.attn.out_proj.weight - torch.Size([64, 64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,089 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.attn.out_proj.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,089 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.sr.weight - torch.Size([64, 64, 8, 8]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,090 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.sr.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,090 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.norm.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,091 - mmcv - INFO - \n","backbone.layers.0.1.0.attn.norm.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,091 - mmcv - INFO - \n","backbone.layers.0.1.0.norm2.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,091 - mmcv - INFO - \n","backbone.layers.0.1.0.norm2.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,092 - mmcv - INFO - \n","backbone.layers.0.1.0.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,093 - mmcv - INFO - \n","backbone.layers.0.1.0.ffn.layers.0.bias - torch.Size([256]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,093 - mmcv - INFO - \n","backbone.layers.0.1.0.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,094 - mmcv - INFO - \n","backbone.layers.0.1.0.ffn.layers.1.bias - torch.Size([256]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,094 - mmcv - INFO - \n","backbone.layers.0.1.0.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,094 - mmcv - INFO - \n","backbone.layers.0.1.0.ffn.layers.4.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,095 - mmcv - INFO - \n","backbone.layers.0.1.1.norm1.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,095 - mmcv - INFO - \n","backbone.layers.0.1.1.norm1.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,095 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.attn.in_proj_weight - torch.Size([192, 64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,095 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.attn.in_proj_bias - torch.Size([192]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,096 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.attn.out_proj.weight - torch.Size([64, 64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,096 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.attn.out_proj.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,096 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.sr.weight - torch.Size([64, 64, 8, 8]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,097 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.sr.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,097 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.norm.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,097 - mmcv - INFO - \n","backbone.layers.0.1.1.attn.norm.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,098 - mmcv - INFO - \n","backbone.layers.0.1.1.norm2.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,098 - mmcv - INFO - \n","backbone.layers.0.1.1.norm2.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,098 - mmcv - INFO - \n","backbone.layers.0.1.1.ffn.layers.0.weight - torch.Size([256, 64, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,099 - mmcv - INFO - \n","backbone.layers.0.1.1.ffn.layers.0.bias - torch.Size([256]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,099 - mmcv - INFO - \n","backbone.layers.0.1.1.ffn.layers.1.weight - torch.Size([256, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,099 - mmcv - INFO - \n","backbone.layers.0.1.1.ffn.layers.1.bias - torch.Size([256]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,100 - mmcv - INFO - \n","backbone.layers.0.1.1.ffn.layers.4.weight - torch.Size([64, 256, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,100 - mmcv - INFO - \n","backbone.layers.0.1.1.ffn.layers.4.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,100 - mmcv - INFO - \n","backbone.layers.0.2.weight - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,100 - mmcv - INFO - \n","backbone.layers.0.2.bias - torch.Size([64]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,101 - mmcv - INFO - \n","backbone.layers.1.0.projection.weight - torch.Size([128, 64, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,101 - mmcv - INFO - \n","backbone.layers.1.0.projection.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,102 - mmcv - INFO - \n","backbone.layers.1.0.norm.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,102 - mmcv - INFO - \n","backbone.layers.1.0.norm.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,102 - mmcv - INFO - \n","backbone.layers.1.1.0.norm1.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,103 - mmcv - INFO - \n","backbone.layers.1.1.0.norm1.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,103 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.attn.in_proj_weight - torch.Size([384, 128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,103 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.attn.in_proj_bias - torch.Size([384]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,103 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.attn.out_proj.weight - torch.Size([128, 128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,104 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.attn.out_proj.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,104 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,105 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.sr.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,105 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.norm.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,105 - mmcv - INFO - \n","backbone.layers.1.1.0.attn.norm.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,106 - mmcv - INFO - \n","backbone.layers.1.1.0.norm2.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,106 - mmcv - INFO - \n","backbone.layers.1.1.0.norm2.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,106 - mmcv - INFO - \n","backbone.layers.1.1.0.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,107 - mmcv - INFO - \n","backbone.layers.1.1.0.ffn.layers.0.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,107 - mmcv - INFO - \n","backbone.layers.1.1.0.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,107 - mmcv - INFO - \n","backbone.layers.1.1.0.ffn.layers.1.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,108 - mmcv - INFO - \n","backbone.layers.1.1.0.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,108 - mmcv - INFO - \n","backbone.layers.1.1.0.ffn.layers.4.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,108 - mmcv - INFO - \n","backbone.layers.1.1.1.norm1.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,109 - mmcv - INFO - \n","backbone.layers.1.1.1.norm1.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,109 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.attn.in_proj_weight - torch.Size([384, 128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,109 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.attn.in_proj_bias - torch.Size([384]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,110 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.attn.out_proj.weight - torch.Size([128, 128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,110 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.attn.out_proj.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,110 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.sr.weight - torch.Size([128, 128, 4, 4]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,110 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.sr.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,111 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.norm.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,111 - mmcv - INFO - \n","backbone.layers.1.1.1.attn.norm.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,112 - mmcv - INFO - \n","backbone.layers.1.1.1.norm2.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,112 - mmcv - INFO - \n","backbone.layers.1.1.1.norm2.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,112 - mmcv - INFO - \n","backbone.layers.1.1.1.ffn.layers.0.weight - torch.Size([512, 128, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,112 - mmcv - INFO - \n","backbone.layers.1.1.1.ffn.layers.0.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,113 - mmcv - INFO - \n","backbone.layers.1.1.1.ffn.layers.1.weight - torch.Size([512, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,113 - mmcv - INFO - \n","backbone.layers.1.1.1.ffn.layers.1.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,113 - mmcv - INFO - \n","backbone.layers.1.1.1.ffn.layers.4.weight - torch.Size([128, 512, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,114 - mmcv - INFO - \n","backbone.layers.1.1.1.ffn.layers.4.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,114 - mmcv - INFO - \n","backbone.layers.1.2.weight - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,115 - mmcv - INFO - \n","backbone.layers.1.2.bias - torch.Size([128]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,116 - mmcv - INFO - \n","backbone.layers.2.0.projection.weight - torch.Size([320, 128, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,117 - mmcv - INFO - \n","backbone.layers.2.0.projection.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,118 - mmcv - INFO - \n","backbone.layers.2.0.norm.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,118 - mmcv - INFO - \n","backbone.layers.2.0.norm.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,120 - mmcv - INFO - \n","backbone.layers.2.1.0.norm1.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,120 - mmcv - INFO - \n","backbone.layers.2.1.0.norm1.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,121 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.attn.in_proj_weight - torch.Size([960, 320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,122 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.attn.in_proj_bias - torch.Size([960]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,127 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.attn.out_proj.weight - torch.Size([320, 320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,127 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.attn.out_proj.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,128 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,128 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.sr.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,129 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.norm.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,129 - mmcv - INFO - \n","backbone.layers.2.1.0.attn.norm.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,129 - mmcv - INFO - \n","backbone.layers.2.1.0.norm2.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,130 - mmcv - INFO - \n","backbone.layers.2.1.0.norm2.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,131 - mmcv - INFO - \n","backbone.layers.2.1.0.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,131 - mmcv - INFO - \n","backbone.layers.2.1.0.ffn.layers.0.bias - torch.Size([1280]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,132 - mmcv - INFO - \n","backbone.layers.2.1.0.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,132 - mmcv - INFO - \n","backbone.layers.2.1.0.ffn.layers.1.bias - torch.Size([1280]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,132 - mmcv - INFO - \n","backbone.layers.2.1.0.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,133 - mmcv - INFO - \n","backbone.layers.2.1.0.ffn.layers.4.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,133 - mmcv - INFO - \n","backbone.layers.2.1.1.norm1.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,134 - mmcv - INFO - \n","backbone.layers.2.1.1.norm1.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,134 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.attn.in_proj_weight - torch.Size([960, 320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,135 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.attn.in_proj_bias - torch.Size([960]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,135 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.attn.out_proj.weight - torch.Size([320, 320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,135 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.attn.out_proj.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,136 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.sr.weight - torch.Size([320, 320, 2, 2]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,136 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.sr.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,137 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.norm.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,137 - mmcv - INFO - \n","backbone.layers.2.1.1.attn.norm.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,137 - mmcv - INFO - \n","backbone.layers.2.1.1.norm2.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,138 - mmcv - INFO - \n","backbone.layers.2.1.1.norm2.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,138 - mmcv - INFO - \n","backbone.layers.2.1.1.ffn.layers.0.weight - torch.Size([1280, 320, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,139 - mmcv - INFO - \n","backbone.layers.2.1.1.ffn.layers.0.bias - torch.Size([1280]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,140 - mmcv - INFO - \n","backbone.layers.2.1.1.ffn.layers.1.weight - torch.Size([1280, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,140 - mmcv - INFO - \n","backbone.layers.2.1.1.ffn.layers.1.bias - torch.Size([1280]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,140 - mmcv - INFO - \n","backbone.layers.2.1.1.ffn.layers.4.weight - torch.Size([320, 1280, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,140 - mmcv - INFO - \n","backbone.layers.2.1.1.ffn.layers.4.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,141 - mmcv - INFO - \n","backbone.layers.2.2.weight - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,141 - mmcv - INFO - \n","backbone.layers.2.2.bias - torch.Size([320]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,141 - mmcv - INFO - \n","backbone.layers.3.0.projection.weight - torch.Size([512, 320, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,142 - mmcv - INFO - \n","backbone.layers.3.0.projection.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,142 - mmcv - INFO - \n","backbone.layers.3.0.norm.weight - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,142 - mmcv - INFO - \n","backbone.layers.3.0.norm.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,146 - mmcv - INFO - \n","backbone.layers.3.1.0.norm1.weight - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,147 - mmcv - INFO - \n","backbone.layers.3.1.0.norm1.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,147 - mmcv - INFO - \n","backbone.layers.3.1.0.attn.attn.in_proj_weight - torch.Size([1536, 512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,147 - mmcv - INFO - \n","backbone.layers.3.1.0.attn.attn.in_proj_bias - torch.Size([1536]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,148 - mmcv - INFO - \n","backbone.layers.3.1.0.attn.attn.out_proj.weight - torch.Size([512, 512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,148 - mmcv - INFO - \n","backbone.layers.3.1.0.attn.attn.out_proj.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,149 - mmcv - INFO - \n","backbone.layers.3.1.0.norm2.weight - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,149 - mmcv - INFO - \n","backbone.layers.3.1.0.norm2.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,150 - mmcv - INFO - \n","backbone.layers.3.1.0.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,150 - mmcv - INFO - \n","backbone.layers.3.1.0.ffn.layers.0.bias - torch.Size([2048]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,151 - mmcv - INFO - \n","backbone.layers.3.1.0.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,151 - mmcv - INFO - \n","backbone.layers.3.1.0.ffn.layers.1.bias - torch.Size([2048]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,152 - mmcv - INFO - \n","backbone.layers.3.1.0.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,152 - mmcv - INFO - \n","backbone.layers.3.1.0.ffn.layers.4.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,153 - mmcv - INFO - \n","backbone.layers.3.1.1.norm1.weight - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,153 - mmcv - INFO - \n","backbone.layers.3.1.1.norm1.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,154 - mmcv - INFO - \n","backbone.layers.3.1.1.attn.attn.in_proj_weight - torch.Size([1536, 512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,154 - mmcv - INFO - \n","backbone.layers.3.1.1.attn.attn.in_proj_bias - torch.Size([1536]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,155 - mmcv - INFO - \n","backbone.layers.3.1.1.attn.attn.out_proj.weight - torch.Size([512, 512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,155 - mmcv - INFO - \n","backbone.layers.3.1.1.attn.attn.out_proj.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,156 - mmcv - INFO - \n","backbone.layers.3.1.1.norm2.weight - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,156 - mmcv - INFO - \n","backbone.layers.3.1.1.norm2.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,157 - mmcv - INFO - \n","backbone.layers.3.1.1.ffn.layers.0.weight - torch.Size([2048, 512, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,157 - mmcv - INFO - \n","backbone.layers.3.1.1.ffn.layers.0.bias - torch.Size([2048]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,158 - mmcv - INFO - \n","backbone.layers.3.1.1.ffn.layers.1.weight - torch.Size([2048, 1, 3, 3]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,158 - mmcv - INFO - \n","backbone.layers.3.1.1.ffn.layers.1.bias - torch.Size([2048]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,158 - mmcv - INFO - \n","backbone.layers.3.1.1.ffn.layers.4.weight - torch.Size([512, 2048, 1, 1]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,159 - mmcv - INFO - \n","backbone.layers.3.1.1.ffn.layers.4.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,159 - mmcv - INFO - \n","backbone.layers.3.2.weight - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,160 - mmcv - INFO - \n","backbone.layers.3.2.bias - torch.Size([512]): \n","PretrainedInit: load from pretrained/mit_b1_mmseg.pth \n"," \n","2023-01-09 03:37:39,160 - mmcv - INFO - \n","decode_head.decoder1_temp - torch.Size([1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,161 - mmcv - INFO - \n","decode_head.decoder2_temp - torch.Size([1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,161 - mmcv - INFO - \n","decode_head.decoder3_temp - torch.Size([1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,161 - mmcv - INFO - \n","decode_head.decoder4_temp - torch.Size([1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,162 - mmcv - INFO - \n","decode_head.decoder5_temp - torch.Size([1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,163 - mmcv - INFO - \n","decode_head.conv_seg.weight - torch.Size([1, 128, 1, 1]): \n","NormalInit: mean=0, std=0.01, bias=0 \n"," \n","2023-01-09 03:37:39,163 - mmcv - INFO - \n","decode_head.conv_seg.bias - torch.Size([1]): \n","NormalInit: mean=0, std=0.01, bias=0 \n"," \n","2023-01-09 03:37:39,164 - mmcv - INFO - \n","decode_head.ASPP.reduction1.module.0.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,164 - mmcv - INFO - \n","decode_head.ASPP.reduction1.module.0.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,164 - mmcv - INFO - \n","decode_head.ASPP.reduction1.module.2.weight - torch.Size([256, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,165 - mmcv - INFO - \n","decode_head.ASPP.aspp_d3.0.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,165 - mmcv - INFO - \n","decode_head.ASPP.aspp_d3.0.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,166 - mmcv - INFO - \n","decode_head.ASPP.aspp_d3.0.module.2.weight - torch.Size([256, 1, 11, 11]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,166 - mmcv - INFO - \n","decode_head.ASPP.aspp_d3.1.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,166 - mmcv - INFO - \n","decode_head.ASPP.aspp_d3.1.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,167 - mmcv - INFO - \n","decode_head.ASPP.aspp_d3.1.module.2.weight - torch.Size([256, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,167 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc1.module.0.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,168 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc1.module.0.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,168 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc1.module.2.weight - torch.Size([256, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,168 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc1.module.2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,169 - mmcv - INFO - \n","decode_head.ASPP.aspp_d6.0.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,169 - mmcv - INFO - \n","decode_head.ASPP.aspp_d6.0.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,170 - mmcv - INFO - \n","decode_head.ASPP.aspp_d6.0.module.2.weight - torch.Size([256, 1, 11, 11]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,170 - mmcv - INFO - \n","decode_head.ASPP.aspp_d6.1.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,171 - mmcv - INFO - \n","decode_head.ASPP.aspp_d6.1.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,171 - mmcv - INFO - \n","decode_head.ASPP.aspp_d6.1.module.2.weight - torch.Size([256, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,171 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc2.module.0.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,172 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc2.module.0.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,172 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc2.module.2.weight - torch.Size([256, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,172 - mmcv - INFO - \n","decode_head.ASPP.attn_reduc2.module.2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,173 - mmcv - INFO - \n","decode_head.ASPP.aspp_d9.0.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,173 - mmcv - INFO - \n","decode_head.ASPP.aspp_d9.0.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,174 - mmcv - INFO - \n","decode_head.ASPP.aspp_d9.0.module.2.weight - torch.Size([256, 1, 11, 11]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,174 - mmcv - INFO - \n","decode_head.ASPP.aspp_d9.1.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,174 - mmcv - INFO - \n","decode_head.ASPP.aspp_d9.1.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,175 - mmcv - INFO - \n","decode_head.ASPP.aspp_d9.1.module.2.weight - torch.Size([256, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,175 - mmcv - INFO - \n","decode_head.ASPP.reduction2.module.0.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,175 - mmcv - INFO - \n","decode_head.ASPP.reduction2.module.0.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,176 - mmcv - INFO - \n","decode_head.ASPP.reduction2.module.2.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,176 - mmcv - INFO - \n","decode_head.psa_1.conv_q_right.weight - torch.Size([1, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,176 - mmcv - INFO - \n","decode_head.psa_1.conv_v_right.weight - torch.Size([128, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,177 - mmcv - INFO - \n","decode_head.psa_1.conv_up.weight - torch.Size([256, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,181 - mmcv - INFO - \n","decode_head.psa_1.conv_q_left.weight - torch.Size([128, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,181 - mmcv - INFO - \n","decode_head.psa_1.conv_v_left.weight - torch.Size([128, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,181 - mmcv - INFO - \n","decode_head.decoder1.0.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,182 - mmcv - INFO - \n","decode_head.decoder1.0.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,182 - mmcv - INFO - \n","decode_head.decoder1.0.module.2.weight - torch.Size([128, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,183 - mmcv - INFO - \n","decode_head.decoder1.1.module.0.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,183 - mmcv - INFO - \n","decode_head.decoder1.1.module.0.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,183 - mmcv - INFO - \n","decode_head.decoder1.1.module.2.weight - torch.Size([64, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,184 - mmcv - INFO - \n","decode_head.decoder1.2.module.0.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,184 - mmcv - INFO - \n","decode_head.decoder1.2.module.0.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,184 - mmcv - INFO - \n","decode_head.decoder1.2.module.2.weight - torch.Size([32, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,185 - mmcv - INFO - \n","decode_head.decoder1.3.module.0.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,185 - mmcv - INFO - \n","decode_head.decoder1.3.module.0.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,186 - mmcv - INFO - \n","decode_head.decoder1.3.module.2.weight - torch.Size([16, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,186 - mmcv - INFO - \n","decode_head.decoder1.4.module.0.weight - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,187 - mmcv - INFO - \n","decode_head.decoder1.4.module.0.bias - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,187 - mmcv - INFO - \n","decode_head.decoder1.4.module.2.weight - torch.Size([1, 16, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,189 - mmcv - INFO - \n","decode_head.decoder2_up1.conv.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,189 - mmcv - INFO - \n","decode_head.decoder2_up1.norm.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,190 - mmcv - INFO - \n","decode_head.decoder2_up1.norm.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,190 - mmcv - INFO - \n","decode_head.decoder2_attn.conv_q_right.weight - torch.Size([1, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,191 - mmcv - INFO - \n","decode_head.decoder2_attn.conv_v_right.weight - torch.Size([128, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,191 - mmcv - INFO - \n","decode_head.decoder2_attn.conv_up.weight - torch.Size([256, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,191 - mmcv - INFO - \n","decode_head.decoder2_attn.conv_q_left.weight - torch.Size([128, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,192 - mmcv - INFO - \n","decode_head.decoder2_attn.conv_v_left.weight - torch.Size([128, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,192 - mmcv - INFO - \n","decode_head.decoder2_reduc1.module.0.weight - torch.Size([579]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,192 - mmcv - INFO - \n","decode_head.decoder2_reduc1.module.0.bias - torch.Size([579]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,193 - mmcv - INFO - \n","decode_head.decoder2_reduc1.module.2.weight - torch.Size([256, 579, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,193 - mmcv - INFO - \n","decode_head.decoder2_1.module.0.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,193 - mmcv - INFO - \n","decode_head.decoder2_1.module.0.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,194 - mmcv - INFO - \n","decode_head.decoder2_1.module.2.weight - torch.Size([128, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,194 - mmcv - INFO - \n","decode_head.decoder2_2.module.0.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,194 - mmcv - INFO - \n","decode_head.decoder2_2.module.0.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,195 - mmcv - INFO - \n","decode_head.decoder2_2.module.2.weight - torch.Size([64, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,195 - mmcv - INFO - \n","decode_head.decoder2_3.module.0.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,195 - mmcv - INFO - \n","decode_head.decoder2_3.module.0.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,196 - mmcv - INFO - \n","decode_head.decoder2_3.module.2.weight - torch.Size([32, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,196 - mmcv - INFO - \n","decode_head.decoder2_4.module.0.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,197 - mmcv - INFO - \n","decode_head.decoder2_4.module.0.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,197 - mmcv - INFO - \n","decode_head.decoder2_4.module.2.weight - torch.Size([16, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,197 - mmcv - INFO - \n","decode_head.decoder2_5.module.0.weight - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,198 - mmcv - INFO - \n","decode_head.decoder2_5.module.0.bias - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,198 - mmcv - INFO - \n","decode_head.decoder2_5.module.2.weight - torch.Size([1, 16, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,198 - mmcv - INFO - \n","decode_head.decoder3_up2.conv.weight - torch.Size([128, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,199 - mmcv - INFO - \n","decode_head.decoder3_up2.norm.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,199 - mmcv - INFO - \n","decode_head.decoder3_up2.norm.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,199 - mmcv - INFO - \n","decode_head.decoder3_attn.conv_q_right.weight - torch.Size([1, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,200 - mmcv - INFO - \n","decode_head.decoder3_attn.conv_v_right.weight - torch.Size([64, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,200 - mmcv - INFO - \n","decode_head.decoder3_attn.conv_up.weight - torch.Size([128, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,200 - mmcv - INFO - \n","decode_head.decoder3_attn.conv_q_left.weight - torch.Size([64, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,201 - mmcv - INFO - \n","decode_head.decoder3_attn.conv_v_left.weight - torch.Size([64, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,201 - mmcv - INFO - \n","decode_head.decoder3_reduc2.module.0.weight - torch.Size([259]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,201 - mmcv - INFO - \n","decode_head.decoder3_reduc2.module.0.bias - torch.Size([259]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,202 - mmcv - INFO - \n","decode_head.decoder3_reduc2.module.2.weight - torch.Size([128, 259, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,202 - mmcv - INFO - \n","decode_head.decoder3_1.module.0.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,202 - mmcv - INFO - \n","decode_head.decoder3_1.module.0.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,203 - mmcv - INFO - \n","decode_head.decoder3_1.module.2.weight - torch.Size([64, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,203 - mmcv - INFO - \n","decode_head.decoder3_2.module.0.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,203 - mmcv - INFO - \n","decode_head.decoder3_2.module.0.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,204 - mmcv - INFO - \n","decode_head.decoder3_2.module.2.weight - torch.Size([32, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,204 - mmcv - INFO - \n","decode_head.decoder3_3.module.0.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,204 - mmcv - INFO - \n","decode_head.decoder3_3.module.0.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,205 - mmcv - INFO - \n","decode_head.decoder3_3.module.2.weight - torch.Size([16, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,205 - mmcv - INFO - \n","decode_head.decoder3_4.module.0.weight - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,206 - mmcv - INFO - \n","decode_head.decoder3_4.module.0.bias - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,206 - mmcv - INFO - \n","decode_head.decoder3_4.module.2.weight - torch.Size([1, 16, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,206 - mmcv - INFO - \n","decode_head.decoder4_up3.conv.weight - torch.Size([64, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,207 - mmcv - INFO - \n","decode_head.decoder4_up3.norm.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,207 - mmcv - INFO - \n","decode_head.decoder4_up3.norm.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,207 - mmcv - INFO - \n","decode_head.decoder4_attn.conv_q_right.weight - torch.Size([1, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,208 - mmcv - INFO - \n","decode_head.decoder4_attn.conv_v_right.weight - torch.Size([32, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,208 - mmcv - INFO - \n","decode_head.decoder4_attn.conv_up.weight - torch.Size([64, 32, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,208 - mmcv - INFO - \n","decode_head.decoder4_attn.conv_q_left.weight - torch.Size([32, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,209 - mmcv - INFO - \n","decode_head.decoder4_attn.conv_v_left.weight - torch.Size([32, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,209 - mmcv - INFO - \n","decode_head.decoder4_reduc3.module.0.weight - torch.Size([131]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,209 - mmcv - INFO - \n","decode_head.decoder4_reduc3.module.0.bias - torch.Size([131]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,210 - mmcv - INFO - \n","decode_head.decoder4_reduc3.module.2.weight - torch.Size([64, 131, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,210 - mmcv - INFO - \n","decode_head.decoder4_1.module.0.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,210 - mmcv - INFO - \n","decode_head.decoder4_1.module.0.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,211 - mmcv - INFO - \n","decode_head.decoder4_1.module.2.weight - torch.Size([32, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,211 - mmcv - INFO - \n","decode_head.decoder4_2.module.0.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,211 - mmcv - INFO - \n","decode_head.decoder4_2.module.0.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,212 - mmcv - INFO - \n","decode_head.decoder4_2.module.2.weight - torch.Size([16, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,212 - mmcv - INFO - \n","decode_head.decoder4_3.module.0.weight - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,212 - mmcv - INFO - \n","decode_head.decoder4_3.module.0.bias - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,213 - mmcv - INFO - \n","decode_head.decoder4_3.module.2.weight - torch.Size([1, 16, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,213 - mmcv - INFO - \n","decode_head.decoder5_up4.conv.weight - torch.Size([32, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,214 - mmcv - INFO - \n","decode_head.decoder5_up4.norm.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,214 - mmcv - INFO - \n","decode_head.decoder5_up4.norm.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,214 - mmcv - INFO - \n","decode_head.decoder5_attn.conv_q_right.weight - torch.Size([1, 32, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,215 - mmcv - INFO - \n","decode_head.decoder5_attn.conv_v_right.weight - torch.Size([16, 32, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,216 - mmcv - INFO - \n","decode_head.decoder5_attn.conv_up.weight - torch.Size([32, 16, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,216 - mmcv - INFO - \n","decode_head.decoder5_attn.conv_q_left.weight - torch.Size([16, 32, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,217 - mmcv - INFO - \n","decode_head.decoder5_attn.conv_v_left.weight - torch.Size([16, 32, 1, 1]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,217 - mmcv - INFO - \n","decode_head.decoder5_reduc4.module.0.weight - torch.Size([35]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,217 - mmcv - INFO - \n","decode_head.decoder5_reduc4.module.0.bias - torch.Size([35]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,218 - mmcv - INFO - \n","decode_head.decoder5_reduc4.module.2.weight - torch.Size([32, 35, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,218 - mmcv - INFO - \n","decode_head.decoder5_1.module.0.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,218 - mmcv - INFO - \n","decode_head.decoder5_1.module.0.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,219 - mmcv - INFO - \n","decode_head.decoder5_1.module.2.weight - torch.Size([16, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,219 - mmcv - INFO - \n","decode_head.decoder5_2.module.0.weight - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,219 - mmcv - INFO - \n","decode_head.decoder5_2.module.0.bias - torch.Size([16]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n","2023-01-09 03:37:39,220 - mmcv - INFO - \n","decode_head.decoder5_2.module.2.weight - torch.Size([1, 16, 3, 3]): \n","The value is the same before and after calling `init_weights` of SunSegmentor  \n"," \n"]},{"name":"stdout","output_type":"stream","text":["#################### Start Training ####################\n"]},{"name":"stderr","output_type":"stream","text":["/home/nguyen.van.quan/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"]},{"name":"stdout","output_type":"stream","text":["2023-01-09 03:40:50.198157 Training Epoch [001/020], [loss: 2.6127, dice: 0.8152, iou: 0.6943]\n","[Saving Checkpoint:] run/test/ColonFormerB4/last.pth\n","####################\n","Dataset_name: Kvasir\n","scores: dice=0.8331712367622537, miou=0.7496770392146545, precision=0.8682838595882381, recall=0.8579024576624572\n","Dataset_name: CVC-ClinicDB\n","scores: dice=0.7613430344557335, miou=0.6711967503626015, precision=0.8022565800783995, recall=0.8044255898888888\n","Dataset_name: CVC-ColonDB\n","scores: dice=0.6564078183398577, miou=0.54951816153832, precision=0.7284840184488995, recall=0.7065402135883325\n","Dataset_name: CVC-300\n","scores: dice=0.8052087174475677, miou=0.7066440335083727, precision=0.836788197344132, recall=0.8227181564226879\n","Dataset_name: ETIS-LaribPolypDB\n","scores: dice=0.5710594247054775, miou=0.4767441417064318, precision=0.5330815315925166, recall=0.790445817790942\n","╒═══════════════════╤══════════╤══════════╕\n","│ Dataset           │      IoU │     Dice │\n","╞═══════════════════╪══════════╪══════════╡\n","│ Kvasir            │ 0.749677 │ 0.833171 │\n","├───────────────────┼──────────┼──────────┤\n","│ CVC-ClinicDB      │ 0.671197 │ 0.761343 │\n","├───────────────────┼──────────┼──────────┤\n","│ CVC-ColonDB       │ 0.549518 │ 0.656408 │\n","├───────────────────┼──────────┼──────────┤\n","│ CVC-300           │ 0.706644 │ 0.805209 │\n","├───────────────────┼──────────┼──────────┤\n","│ ETIS-LaribPolypDB │ 0.476744 │ 0.571059 │\n","├───────────────────┼──────────┼──────────┤\n","│ Total             │ 0.630756 │ 0.725438 │\n","╘═══════════════════╧══════════╧══════════╛\n","####################\n","2023-01-09 03:44:36.896200 Training Epoch [002/020], [loss: 1.9107, dice: 0.8622, iou: 0.7607]\n","[Saving Checkpoint:] run/test/ColonFormerB4/last.pth\n","####################\n","Dataset_name: Kvasir\n","scores: dice=0.8541378032803264, miou=0.7837608776222733, precision=0.9478879405144037, recall=0.8102504523367989\n","Dataset_name: CVC-ClinicDB\n","scores: dice=0.847559383157422, miou=0.7818521713333597, precision=0.8751277307559984, recall=0.8572913204545445\n","Dataset_name: CVC-ColonDB\n","scores: dice=0.7061967704190593, miou=0.6106159891789058, precision=0.7460976095732148, recall=0.7401592451009354\n","Dataset_name: CVC-300\n","scores: dice=0.8447092939301037, miou=0.7613585229425934, precision=0.8141536707479989, recall=0.9118455388007791\n","Dataset_name: ETIS-LaribPolypDB\n","scores: dice=0.65672546204095, miou=0.5659847095536358, precision=0.6306713186094355, recall=0.7735708027925906\n","╒═══════════════════╤══════════╤══════════╕\n","│ Dataset           │      IoU │     Dice │\n","╞═══════════════════╪══════════╪══════════╡\n","│ Kvasir            │ 0.783761 │ 0.854138 │\n","├───────────────────┼──────────┼──────────┤\n","│ CVC-ClinicDB      │ 0.781852 │ 0.847559 │\n","├───────────────────┼──────────┼──────────┤\n","│ CVC-ColonDB       │ 0.610616 │ 0.706197 │\n","├───────────────────┼──────────┼──────────┤\n","│ CVC-300           │ 0.761359 │ 0.844709 │\n","├───────────────────┼──────────┼──────────┤\n","│ ETIS-LaribPolypDB │ 0.565985 │ 0.656725 │\n","├───────────────────┼──────────┼──────────┤\n","│ Total             │ 0.700714 │ 0.781866 │\n","╘═══════════════════╧══════════╧══════════╛\n","####################\n"]}],"source":["init_lr = 1e-4\n","batchsize = 8\n","trainsize_init = 352\n","clip = 0.5\n","num_epochs= 20\n","train_save = 'ColonFormerB4'\n","\n","save_path = 'run/test/{}/'.format(train_save)\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path, exist_ok=True)\n","else:\n","    print(\"Save path existed\")\n","#     sys.exit(1)\n","\n","\n","log = pd.DataFrame(index=[], columns=[\n","    'epoch', 'lr', 'loss', 'dice', 'iou', 'val_loss', 'val_dice', 'val_iou'\n","])\n","train_img_paths = []\n","train_mask_paths = []\n","train_img_paths = glob.glob('/home/nguyen.van.quan/scatsimclr/TrainDataset/image/*')\n","train_mask_paths = glob.glob('/home/nguyen.van.quan/scatsimclr/TrainDataset/mask/*')\n","train_img_paths.sort()\n","train_mask_paths.sort()\n","\n","train_dataset = Dataset(train_img_paths, train_mask_paths)\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=batchsize,\n","    shuffle=True,\n","    pin_memory=True,\n","    drop_last=True\n",")\n","\n","total_step = len(train_loader)\n","model = segformer('b1').cuda(1)\n","\n","# ---- flops and params ----\n","params = model.parameters()\n","optimizer = torch.optim.Adam(params, init_lr)\n","lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n","                                    T_max=len(train_loader)*num_epochs,\n","                                    eta_min=init_lr/1000)\n","\n","\n","\n","start_epoch = 1\n","\n","print(\"#\"*20, f\"Start Training\", \"#\"*20)\n","for epoch in range(start_epoch, num_epochs+1):\n","    train_log = train(train_loader, model, optimizer, epoch, lr_scheduler)\n","\n","\n","    if epoch >= num_epochs-20:\n","        inference(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"PolypFormer B4.ipynb","provenance":[]},"interpreter":{"hash":"b9b35ab1df9b2480d8b627e7b9cec97046ee77a562097ed1d3b1d1b2f663bd17"},"kernelspec":{"display_name":"Python 3.9.15 ('mmseg': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"165993ce3f9d9c0577908c605ebf334a59bf64fb14dc7b37ef5b30c8e5c2a60f"}}},"nbformat":4,"nbformat_minor":0}
